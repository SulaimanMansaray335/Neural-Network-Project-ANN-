{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd090c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "from datetime import datetime \n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import pickle \n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder(sparse_output = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d736197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = pd.read_csv('Churn_modelling.csv')\n",
    "salary = salary.drop(columns = ['RowNumber', 'CustomerId', 'Surname'])\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b9c2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = salary.select_dtypes(include = 'object').columns \n",
    "\n",
    "salary[cols] = salary[cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "954269f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idsx = salary.select_dtypes(include = 'category')\n",
    "for i in idsx:\n",
    "    if len(salary[i].cat.categories) <= 2:\n",
    "        salary[i] = label_encoder_gender.fit_transform(salary[i])\n",
    "    else:\n",
    "        salary[i] = salary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d489b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = one_hot_encoder.fit_transform(salary[['Geography']])\n",
    "\n",
    "geo_df = pd.DataFrame(geo_df, columns = one_hot_encoder.get_feature_names_out(['Geography']))\n",
    "salary = pd.concat([salary.drop(columns = 'Geography'), geo_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc3963f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       0   42       2       0.00              1          1   \n",
       "1             608       0   41       1   83807.86              1          0   \n",
       "2             502       0   42       8  159660.80              3          1   \n",
       "3             699       0   39       1       0.00              2          0   \n",
       "4             850       0   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       1   39       5       0.00              2          1   \n",
       "9996          516       1   35      10   57369.61              1          1   \n",
       "9997          709       0   36       7       0.00              1          0   \n",
       "9998          772       1   42       3   75075.31              2          1   \n",
       "9999          792       0   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1               1.0   \n",
       "1                  1        112542.58       0               0.0   \n",
       "2                  0        113931.57       1               1.0   \n",
       "3                  0         93826.63       0               1.0   \n",
       "4                  1         79084.10       0               0.0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0               1.0   \n",
       "9996               1        101699.77       0               1.0   \n",
       "9997               1         42085.58       1               1.0   \n",
       "9998               0         92888.52       1               0.0   \n",
       "9999               0         38190.78       0               1.0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                   0.0              0.0  \n",
       "1                   0.0              1.0  \n",
       "2                   0.0              0.0  \n",
       "3                   0.0              0.0  \n",
       "4                   0.0              1.0  \n",
       "...                 ...              ...  \n",
       "9995                0.0              0.0  \n",
       "9996                0.0              0.0  \n",
       "9997                0.0              0.0  \n",
       "9998                1.0              0.0  \n",
       "9999                0.0              0.0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28c67c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = salary['EstimatedSalary']\n",
    "x = salary.drop(columns = ['EstimatedSalary'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8247ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.Adam(learning_rate = 0.01)\n",
    "loss = tensorflow.keras.losses.mean_absolute_error\n",
    "\n",
    "def create_model(neurons = 32, layers = 1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation = 'relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = opt, loss = loss, metrics = ['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da1a5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(layers = 1, neurons = 32, build_fn = create_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0d1671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2, 3],\n",
    "    'batch_size': [10, 20],\n",
    "    'epochs': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38c4ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tariq\\Desktop\\Neural Network Project\\venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 99556.5078 - mae: 99556.5078\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 94193.8984 - mae: 94193.8984\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 972us/step - loss: 85735.0312 - mae: 85735.0312\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 960us/step - loss: 76654.3750 - mae: 76654.3828\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 68343.5078 - mae: 68343.5078\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 61663.7695 - mae: 61663.7695\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 56758.0312 - mae: 56758.0312\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 53416.6211 - mae: 53416.6211\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 969us/step - loss: 51464.9258 - mae: 51464.9258\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 881us/step - loss: 50487.9570 - mae: 50487.9570\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 50043.5586 - mae: 50043.5586\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49842.1250 - mae: 49842.1250\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49750.6250 - mae: 49750.6250\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49706.2109 - mae: 49706.2109\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 920us/step - loss: 49676.4453 - mae: 49676.4453\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 913us/step - loss: 49654.6953 - mae: 49654.6953\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 967us/step - loss: 49636.1133 - mae: 49636.1133\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49619.5234 - mae: 49619.5234\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 867us/step - loss: 49602.0742 - mae: 49602.0742\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 916us/step - loss: 49587.1250 - mae: 49587.1250\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 910us/step - loss: 49575.0938 - mae: 49575.0938\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 901us/step - loss: 49560.5781 - mae: 49560.5781\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 899us/step - loss: 49545.5039 - mae: 49545.5078\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 884us/step - loss: 49532.2227 - mae: 49532.2227\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 866us/step - loss: 49522.6562 - mae: 49522.6562\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 857us/step - loss: 49509.3320 - mae: 49509.3320\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 49499.1992 - mae: 49499.1992\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49488.7461 - mae: 49488.7422\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49476.0938 - mae: 49476.0938\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49467.6641 - mae: 49467.6641\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49457.7812 - mae: 49457.7812\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49450.7227 - mae: 49450.7188\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49438.8047 - mae: 49438.8047\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 933us/step - loss: 49432.0352 - mae: 49432.0352\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 922us/step - loss: 49423.3945 - mae: 49423.3945\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 919us/step - loss: 49415.7461 - mae: 49415.7461\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 966us/step - loss: 49408.1445 - mae: 49408.1445\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 968us/step - loss: 49398.8438 - mae: 49398.8438\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 910us/step - loss: 49392.3398 - mae: 49392.3438\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 938us/step - loss: 49386.2930 - mae: 49386.2969\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 902us/step - loss: 49380.1602 - mae: 49380.1602\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 895us/step - loss: 49373.2617 - mae: 49373.2617\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 913us/step - loss: 49366.6836 - mae: 49366.6836\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 957us/step - loss: 49361.4414 - mae: 49361.4414\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 921us/step - loss: 49355.0000 - mae: 49355.0000\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 890us/step - loss: 49350.3320 - mae: 49350.3320\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 878us/step - loss: 49344.8203 - mae: 49344.8203\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 912us/step - loss: 49339.0977 - mae: 49339.0977\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 890us/step - loss: 49333.3867 - mae: 49333.3867\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 896us/step - loss: 49327.5273 - mae: 49327.5312\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 948us/step - loss: 49324.4766 - mae: 49324.4766\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49320.8242 - mae: 49320.8242\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 941us/step - loss: 49315.6133 - mae: 49315.6172\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 945us/step - loss: 49309.4219 - mae: 49309.4219\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 924us/step - loss: 49306.3203 - mae: 49306.3203\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 895us/step - loss: 49303.2148 - mae: 49303.2148\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 902us/step - loss: 49299.5391 - mae: 49299.5391\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 895us/step - loss: 49294.1055 - mae: 49294.1055\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 884us/step - loss: 49291.5039 - mae: 49291.5039\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 892us/step - loss: 49287.9375 - mae: 49287.9375\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 881us/step - loss: 49282.4023 - mae: 49282.4023\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 885us/step - loss: 49277.5859 - mae: 49277.5859\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 891us/step - loss: 49276.3320 - mae: 49276.3320\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 995us/step - loss: 49272.1953 - mae: 49272.1953\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 908us/step - loss: 49269.5742 - mae: 49269.5742\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 901us/step - loss: 49268.3867 - mae: 49268.3867\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 885us/step - loss: 49265.6328 - mae: 49265.6328\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 922us/step - loss: 49263.2539 - mae: 49263.2539\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 902us/step - loss: 49258.7617 - mae: 49258.7617\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 909us/step - loss: 49258.7031 - mae: 49258.7031\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 895us/step - loss: 49255.5469 - mae: 49255.5469\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 913us/step - loss: 49253.3867 - mae: 49253.3867\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 995us/step - loss: 49249.6289 - mae: 49249.6289\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 990us/step - loss: 49249.1367 - mae: 49249.1367\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 971us/step - loss: 49246.9414 - mae: 49246.9414\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49243.8750 - mae: 49243.8750\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 953us/step - loss: 49240.6992 - mae: 49240.6992\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49241.9883 - mae: 49241.9883\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 49238.0352 - mae: 49238.0352\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 49237.9688 - mae: 49237.9688\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49234.2266 - mae: 49234.2266\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 964us/step - loss: 49232.2227 - mae: 49232.2227\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 960us/step - loss: 49232.0195 - mae: 49232.0195\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 956us/step - loss: 49229.1211 - mae: 49229.1211\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 940us/step - loss: 49225.8672 - mae: 49225.8672\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 965us/step - loss: 49224.4414 - mae: 49224.4414\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 950us/step - loss: 49222.9609 - mae: 49222.9609\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 951us/step - loss: 49221.3750 - mae: 49221.3750\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 954us/step - loss: 49220.0430 - mae: 49220.0430\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 944us/step - loss: 49219.3828 - mae: 49219.3828\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 941us/step - loss: 49216.3828 - mae: 49216.3828\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 958us/step - loss: 49216.3320 - mae: 49216.3320\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49215.3359 - mae: 49215.3359\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49214.6562 - mae: 49214.6562\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49210.4102 - mae: 49210.4062\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49207.5234 - mae: 49207.5234\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 966us/step - loss: 49206.9492 - mae: 49206.9492\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 985us/step - loss: 49210.3438 - mae: 49210.3438\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49206.0469 - mae: 49206.0469\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 955us/step - loss: 49204.8125 - mae: 49204.8125\n",
      "Best: -0.013821 using {'batch_size': 10, 'epochs': 100, 'layers': 1, 'neurons': 16}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40b429f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation = 'relu', input_shape = (x_train.shape[1],)),\n",
    "    Dense(1)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0585cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.Adam(learning_rate = 0.01)\n",
    "loss = tensorflow.keras.losses.mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "733c98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = opt, loss = loss, metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e11674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'regressions/fit/' + datetime.now().strftime('%m_%d_%Y_%S_%M_%H')\n",
    "tensorflow_callback = TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52430872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 99561.1406 - mae: 99561.1406 - val_loss: 95440.3438 - val_mae: 95440.3438\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 94120.9297 - mae: 94120.9297 - val_loss: 88036.5547 - val_mae: 88036.5547\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 85472.3516 - mae: 85472.3516 - val_loss: 78765.9062 - val_mae: 78765.9062\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 76033.6719 - mae: 76033.6719 - val_loss: 69705.4141 - val_mae: 69705.4141\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 67377.6016 - mae: 67377.6016 - val_loss: 62181.1562 - val_mae: 62181.1562\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 60441.9062 - mae: 60441.9062 - val_loss: 56737.6836 - val_mae: 56737.6836\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 55504.2852 - mae: 55504.2852 - val_loss: 53581.2344 - val_mae: 53581.2344\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 52384.9062 - mae: 52384.9062 - val_loss: 52126.3398 - val_mae: 52126.3398\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 50747.3984 - mae: 50747.3984 - val_loss: 51561.1094 - val_mae: 51561.1094\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 50042.0234 - mae: 50042.0234 - val_loss: 51355.9102 - val_mae: 51355.9102\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49737.5586 - mae: 49737.5586 - val_loss: 51314.1289 - val_mae: 51314.1289\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49600.2305 - mae: 49600.2305 - val_loss: 51317.3594 - val_mae: 51317.3594\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49539.9570 - mae: 49539.9570 - val_loss: 51305.8047 - val_mae: 51305.8008\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49498.9805 - mae: 49498.9805 - val_loss: 51294.1680 - val_mae: 51294.1641\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49472.3594 - mae: 49472.3594 - val_loss: 51296.6016 - val_mae: 51296.6055\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49451.7422 - mae: 49451.7422 - val_loss: 51283.8906 - val_mae: 51283.8906\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49433.6992 - mae: 49433.6992 - val_loss: 51278.2070 - val_mae: 51278.2070\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49418.4023 - mae: 49418.4023 - val_loss: 51257.1094 - val_mae: 51257.1094\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49404.9883 - mae: 49404.9883 - val_loss: 51237.2617 - val_mae: 51237.2617\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49394.8281 - mae: 49394.8281 - val_loss: 51238.7891 - val_mae: 51238.7891\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49382.5195 - mae: 49382.5195 - val_loss: 51224.0625 - val_mae: 51224.0625\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49372.3125 - mae: 49372.3125 - val_loss: 51223.4336 - val_mae: 51223.4336\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49362.4297 - mae: 49362.4297 - val_loss: 51209.3516 - val_mae: 51209.3516\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49351.0117 - mae: 49351.0117 - val_loss: 51194.8555 - val_mae: 51194.8555\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49342.8633 - mae: 49342.8633 - val_loss: 51189.2344 - val_mae: 51189.2344\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49334.2148 - mae: 49334.2188 - val_loss: 51192.1758 - val_mae: 51192.1758\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49324.9609 - mae: 49324.9609 - val_loss: 51192.7656 - val_mae: 51192.7734\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49320.0430 - mae: 49320.0430 - val_loss: 51185.3867 - val_mae: 51185.3867\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49310.8359 - mae: 49310.8359 - val_loss: 51171.7812 - val_mae: 51171.7812\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49302.7891 - mae: 49302.7891 - val_loss: 51176.8086 - val_mae: 51176.8086\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49296.9766 - mae: 49296.9766 - val_loss: 51177.0312 - val_mae: 51177.0312\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49290.0938 - mae: 49290.0938 - val_loss: 51167.9492 - val_mae: 51167.9453\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49286.0352 - mae: 49286.0352 - val_loss: 51172.6875 - val_mae: 51172.6875\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49280.0156 - mae: 49280.0156 - val_loss: 51158.4727 - val_mae: 51158.4688\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49272.8438 - mae: 49272.8438 - val_loss: 51157.9805 - val_mae: 51157.9805\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49270.1836 - mae: 49270.1836 - val_loss: 51157.1680 - val_mae: 51157.1680\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49264.6484 - mae: 49264.6523 - val_loss: 51157.3789 - val_mae: 51157.3789\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49257.3750 - mae: 49257.3789 - val_loss: 51150.3789 - val_mae: 51150.3789\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49252.2969 - mae: 49252.2969 - val_loss: 51142.1250 - val_mae: 51142.1250\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49249.0000 - mae: 49249.0000 - val_loss: 51133.8164 - val_mae: 51133.8164\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49245.3555 - mae: 49245.3555 - val_loss: 51137.3359 - val_mae: 51137.3359\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49240.4609 - mae: 49240.4609 - val_loss: 51148.4219 - val_mae: 51148.4219\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49234.1250 - mae: 49234.1250 - val_loss: 51133.7773 - val_mae: 51133.7773\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49233.0273 - mae: 49233.0273 - val_loss: 51134.1797 - val_mae: 51134.1797\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49229.4727 - mae: 49229.4727 - val_loss: 51136.3242 - val_mae: 51136.3242\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49223.3906 - mae: 49223.3906 - val_loss: 51138.9102 - val_mae: 51138.9102\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49221.5195 - mae: 49221.5195 - val_loss: 51146.5586 - val_mae: 51146.5586\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49219.0234 - mae: 49219.0234 - val_loss: 51136.1055 - val_mae: 51136.1055\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49217.3242 - mae: 49217.3242 - val_loss: 51146.2812 - val_mae: 51146.2812\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49213.3359 - mae: 49213.3359 - val_loss: 51150.8633 - val_mae: 51150.8633\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49210.1836 - mae: 49210.1836 - val_loss: 51148.6992 - val_mae: 51148.6992\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49209.2109 - mae: 49209.2109 - val_loss: 51145.7461 - val_mae: 51145.7461\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 49206.1445 - mae: 49206.1445 - val_loss: 51148.2383 - val_mae: 51148.2383\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, validation_data = (x_test, y_test), epochs  = 100, batch_size = 10, \n",
    "    callbacks = [tensorflow_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db3ee7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tariq\\Desktop\\Neural Network Project\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9423d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a47c34bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 44596), started 1 day, 6:40:37 ago. (Use '!kill 44596' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4abc40be671caea8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4abc40be671caea8\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c37d5f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 969us/step - loss: 51056.0234 - mae: 51056.0234\n",
      "Test Mae: 51056.0234375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "print(f'Test Mae: {test_mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
